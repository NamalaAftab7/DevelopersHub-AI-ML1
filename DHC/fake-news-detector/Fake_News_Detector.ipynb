{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ✅ Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "import pickle\n",
        "\n",
        "# ✅ Download NLTK Data\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# ✅ Load Dataset\n",
        "df = pd.read_csv(\"/content/news.csv\")  # Make sure to upload your dataset in the same directory\n",
        "\n",
        "# ✅ Define Stopwords and Lemmatizer\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
        "    words = word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]  # Keep stopwords!\n",
        "    return \" \".join(words)\n",
        "\n",
        "# ✅ Apply Text Preprocessing\n",
        "df[\"clean_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# ✅ Convert Labels to Numeric\n",
        "df[\"label\"] = df[\"label\"].fillna(df[\"label\"].mode()[0])\n",
        "df[\"label\"] = df[\"label\"].map({\"REAL\": 0, \"FAKE\": 1})\n",
        "\n",
        "# ✅ Check & Remove Any NaN Labels\n",
        "df = df.dropna(subset=[\"label\"])\n",
        "\n",
        "# ✅ Remove Unnecessary Column\n",
        "if \"Unnamed: 0\" in df.columns:\n",
        "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "# ✅ Shuffle Dataset\n",
        "df = shuffle(df, random_state=42)\n",
        "\n",
        "# ✅ Convert Text to Numerical Features (Reduced Features)\n",
        "vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X = vectorizer.fit_transform(df[\"clean_text\"]).toarray()\n",
        "y = df[\"label\"].values\n",
        "\n",
        "# ✅ Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ✅ Train Naïve Bayes Model (Better for Text Data)\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Predictions & Accuracy\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "print(\"\\n✅ Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# ✅ Save the trained model and vectorizer\n",
        "# Save the Naïve Bayes model\n",
        "with open('nb_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(nb_model, model_file)\n",
        "\n",
        "# Save the TF-IDF Vectorizer\n",
        "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)\n",
        "\n",
        "print(\"Model and vectorizer saved successfully!\")\n",
        "\n",
        "# ✅ Prediction Function\n",
        "def predict_news(news_text):\n",
        "    processed_text = preprocess_text(news_text)\n",
        "    transformed_text = vectorizer.transform([processed_text]).toarray()\n",
        "    prediction = nb_model.predict(transformed_text)\n",
        "    confidence = nb_model.predict_proba(transformed_text)\n",
        "    label = \"Fake News ❌\" if prediction[0] == 1 else \"Real News ✅\"\n",
        "    return f\"Processed Input: {processed_text}\\nPrediction: {label}\\nConfidence: {confidence}\"\n",
        "\n",
        "# ✅ Test with a Sample News Article\n",
        "news_text = \"\"\"The President of the United States met with world leaders today to discuss climate change policies.\n",
        "The summit focused on reducing carbon emissions and increasing green energy investments.\"\"\"\n",
        "print(predict_news(news_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i76SyaK3UshA",
        "outputId": "d8698cbd-9bdc-45d9-f338-fa87c54203a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Naïve Bayes Accuracy: 0.857969489742241\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85       930\n",
            "           1       0.85      0.87      0.86       971\n",
            "\n",
            "    accuracy                           0.86      1901\n",
            "   macro avg       0.86      0.86      0.86      1901\n",
            "weighted avg       0.86      0.86      0.86      1901\n",
            "\n",
            "Model and vectorizer saved successfully!\n",
            "Processed Input: the president of the united state met with world leader today to discus climate change policy the summit focused on reducing carbon emission and increasing green energy investment\n",
            "Prediction: Real News ✅\n",
            "Confidence: [[0.66602737 0.33397263]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Save the trained model and vectorizer\n",
        "# Save the Naïve Bayes model\n",
        "with open('nb_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(nb_model, model_file)\n",
        "\n",
        "# Save the TF-IDF Vectorizer\n",
        "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)\n",
        "\n",
        "print(\"Model and vectorizer saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yByXitl-a_9W",
        "outputId": "e3f2a8ce-a684-4fb0-e7fd-b1043d82e3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and vectorizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the model and vectorizer\n",
        "files.download('nb_model.pkl')\n",
        "files.download('vectorizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pEpa_ms1bBh3",
        "outputId": "d5071431-64a6-4463-a195-0e4f64afe965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3000272c-04bc-4a3e-bacd-ac2c9aeb0148\", \"nb_model.pkl\", 96608)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8698bb34-00f5-4f3c-82d9-1c0b59c02f78\", \"vectorizer.pkl\", 109886)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}